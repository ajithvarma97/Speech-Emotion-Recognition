{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Flatten, Dropout, Activation\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name, mfcc, chroma, mel):\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate=sound_file.samplerate\n",
    "        if chroma:\n",
    "            stft=np.abs(librosa.stft(X))\n",
    "        result=np.array([])\n",
    "        if mfcc:\n",
    "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result=np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, mel))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}\n",
    "\n",
    "#DataFlair - Emotions to observe\n",
    "observed_emotions=['calm', 'happy', 'fearful', 'disgust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(test_size=0.2):\n",
    "    x,y=[],[]\n",
    "    for file in glob.glob(\"C:\\\\Speech Emotion\\\\RAVESS\\\\Actor_*\\\\*.wav\"):\n",
    "        file_name=os.path.basename(file)\n",
    "        emotion=emotions[file_name.split(\"-\")[2]]\n",
    "        if emotion not in observed_emotions:\n",
    "            continue\n",
    "        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "        x.append(feature)\n",
    "        y.append(int(file_name[7:8]) - 1)\n",
    "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=load_data(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincnn = np.expand_dims(x_train, axis=2)\n",
    "x_testcnn = np.expand_dims(x_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajithvarma\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model1.add(Conv1D(16, 7,padding='same',strides=2,\n",
    "                 input_shape=(180,1)))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Conv1D(32, 5,padding='same',strides=2 ,))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Conv1D(64, 3,padding='same',strides=2 ,))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Conv1D(128, 3,padding='same',strides=2 ,))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Conv1D(128, 3,padding='same',strides=2 ,))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Dropout(0.25))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(512))\n",
    "model1.add(Dense(8))\n",
    "model1.add(Activation('softmax'))\n",
    "opt1 = RMSprop(lr=0.00005, rho=0.9, epsilon=None, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 90, 16)            128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 90, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 45, 32)            2592      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 45, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 23, 64)            6208      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 23, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 12, 128)           24704     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 12, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 6, 128)            49280     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               393728    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 4104      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 480,744\n",
      "Trainable params: 480,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt1,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/550\n",
      "39/39 [==============================] - 2s 28ms/step - loss: 1.6144 - accuracy: 0.2492 - val_loss: 1.3807 - val_accuracy: 0.3571\n",
      "Epoch 2/550\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 1.4184 - accuracy: 0.2932 - val_loss: 1.3169 - val_accuracy: 0.4610\n",
      "Epoch 3/550\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 1.3709 - accuracy: 0.3176 - val_loss: 1.2923 - val_accuracy: 0.4286\n",
      "Epoch 4/550\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 1.3278 - accuracy: 0.3388 - val_loss: 1.2971 - val_accuracy: 0.3961\n",
      "Epoch 5/550\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 1.2903 - accuracy: 0.3746 - val_loss: 1.2235 - val_accuracy: 0.4351\n",
      "Epoch 6/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 1.2471 - accuracy: 0.4055 - val_loss: 1.2317 - val_accuracy: 0.4481\n",
      "Epoch 7/550\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 1.2126 - accuracy: 0.4381 - val_loss: 1.2066 - val_accuracy: 0.4740\n",
      "Epoch 8/550\n",
      "39/39 [==============================] - 1s 18ms/step - loss: 1.1914 - accuracy: 0.4463 - val_loss: 1.1628 - val_accuracy: 0.4870\n",
      "Epoch 9/550\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 1.1727 - accuracy: 0.4479 - val_loss: 1.1395 - val_accuracy: 0.4935\n",
      "Epoch 10/550\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 1.1612 - accuracy: 0.4511 - val_loss: 1.1266 - val_accuracy: 0.4610\n",
      "Epoch 11/550\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 1.1384 - accuracy: 0.5000 - val_loss: 1.1275 - val_accuracy: 0.5130\n",
      "Epoch 12/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 1.1139 - accuracy: 0.4756 - val_loss: 1.1422 - val_accuracy: 0.4481\n",
      "Epoch 13/550\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 1.1099 - accuracy: 0.4951 - val_loss: 1.1146 - val_accuracy: 0.5065\n",
      "Epoch 14/550\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 1.0947 - accuracy: 0.5000 - val_loss: 1.1064 - val_accuracy: 0.4416\n",
      "Epoch 15/550\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 1.0782 - accuracy: 0.5065 - val_loss: 1.1061 - val_accuracy: 0.5714\n",
      "Epoch 16/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.0581 - accuracy: 0.5261 - val_loss: 1.0821 - val_accuracy: 0.5130\n",
      "Epoch 17/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.0646 - accuracy: 0.5147 - val_loss: 1.0545 - val_accuracy: 0.5325\n",
      "Epoch 18/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.0501 - accuracy: 0.5326 - val_loss: 1.0506 - val_accuracy: 0.5325\n",
      "Epoch 19/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.0231 - accuracy: 0.5277 - val_loss: 1.0460 - val_accuracy: 0.5065\n",
      "Epoch 20/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.0155 - accuracy: 0.5668 - val_loss: 1.0215 - val_accuracy: 0.5584\n",
      "Epoch 21/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.9946 - accuracy: 0.5651 - val_loss: 1.0262 - val_accuracy: 0.5584\n",
      "Epoch 22/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.0038 - accuracy: 0.5570 - val_loss: 1.0483 - val_accuracy: 0.5519\n",
      "Epoch 23/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.9767 - accuracy: 0.5700 - val_loss: 1.0877 - val_accuracy: 0.4740\n",
      "Epoch 24/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.9959 - accuracy: 0.5537 - val_loss: 0.9937 - val_accuracy: 0.5455\n",
      "Epoch 25/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.9676 - accuracy: 0.5651 - val_loss: 0.9969 - val_accuracy: 0.5779\n",
      "Epoch 26/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.9594 - accuracy: 0.5717 - val_loss: 1.0310 - val_accuracy: 0.5714\n",
      "Epoch 27/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.9574 - accuracy: 0.5863 - val_loss: 0.9838 - val_accuracy: 0.5584\n",
      "Epoch 28/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.9482 - accuracy: 0.5993 - val_loss: 1.0523 - val_accuracy: 0.5260\n",
      "Epoch 29/550\n",
      "39/39 [==============================] - 1s 12ms/step - loss: 0.9293 - accuracy: 0.6042 - val_loss: 0.9842 - val_accuracy: 0.5714\n",
      "Epoch 30/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.9198 - accuracy: 0.6091 - val_loss: 0.9614 - val_accuracy: 0.5649\n",
      "Epoch 31/550\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.9072 - accuracy: 0.6075 - val_loss: 0.9483 - val_accuracy: 0.5649\n",
      "Epoch 32/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.9053 - accuracy: 0.6352 - val_loss: 0.9415 - val_accuracy: 0.5974\n",
      "Epoch 33/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.8972 - accuracy: 0.6107 - val_loss: 0.9886 - val_accuracy: 0.5584\n",
      "Epoch 34/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.8830 - accuracy: 0.6238 - val_loss: 0.9530 - val_accuracy: 0.5714\n",
      "Epoch 35/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.8979 - accuracy: 0.6156 - val_loss: 0.9486 - val_accuracy: 0.5584\n",
      "Epoch 36/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.8885 - accuracy: 0.6205 - val_loss: 0.9296 - val_accuracy: 0.5974\n",
      "Epoch 37/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.8662 - accuracy: 0.6498 - val_loss: 0.9268 - val_accuracy: 0.6234\n",
      "Epoch 38/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.8546 - accuracy: 0.6466 - val_loss: 0.9262 - val_accuracy: 0.6169\n",
      "Epoch 39/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.8398 - accuracy: 0.6547 - val_loss: 0.9155 - val_accuracy: 0.5974\n",
      "Epoch 40/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.8317 - accuracy: 0.6857 - val_loss: 0.9110 - val_accuracy: 0.5974\n",
      "Epoch 41/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.8488 - accuracy: 0.6450 - val_loss: 0.8972 - val_accuracy: 0.6169\n",
      "Epoch 42/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.8311 - accuracy: 0.6564 - val_loss: 0.8973 - val_accuracy: 0.6104\n",
      "Epoch 43/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.8134 - accuracy: 0.6775 - val_loss: 0.9005 - val_accuracy: 0.6104\n",
      "Epoch 44/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.8105 - accuracy: 0.6678 - val_loss: 0.8763 - val_accuracy: 0.6558\n",
      "Epoch 45/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.8045 - accuracy: 0.6726 - val_loss: 0.8794 - val_accuracy: 0.6429\n",
      "Epoch 46/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.7853 - accuracy: 0.6971 - val_loss: 0.8875 - val_accuracy: 0.6169\n",
      "Epoch 47/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.7891 - accuracy: 0.6922 - val_loss: 0.8702 - val_accuracy: 0.6299\n",
      "Epoch 48/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.7770 - accuracy: 0.6971 - val_loss: 0.8586 - val_accuracy: 0.6234\n",
      "Epoch 49/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.7541 - accuracy: 0.6873 - val_loss: 0.8723 - val_accuracy: 0.5974\n",
      "Epoch 50/550\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.7703 - accuracy: 0.6824 - val_loss: 0.9832 - val_accuracy: 0.5649\n",
      "Epoch 51/550\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.7361 - accuracy: 0.7166 - val_loss: 0.8751 - val_accuracy: 0.5974\n",
      "Epoch 52/550\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.7363 - accuracy: 0.7020 - val_loss: 0.8559 - val_accuracy: 0.6104\n",
      "Epoch 53/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.7232 - accuracy: 0.7150 - val_loss: 0.8725 - val_accuracy: 0.5909\n",
      "Epoch 54/550\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.7209 - accuracy: 0.7215 - val_loss: 0.8536 - val_accuracy: 0.6299\n",
      "Epoch 55/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.7072 - accuracy: 0.7166 - val_loss: 0.8529 - val_accuracy: 0.6169\n",
      "Epoch 56/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.7090 - accuracy: 0.7101 - val_loss: 0.8587 - val_accuracy: 0.6299\n",
      "Epoch 57/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6978 - accuracy: 0.7362 - val_loss: 0.8747 - val_accuracy: 0.6429\n",
      "Epoch 58/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6806 - accuracy: 0.7296 - val_loss: 0.8617 - val_accuracy: 0.6234\n",
      "Epoch 59/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6825 - accuracy: 0.7394 - val_loss: 0.8416 - val_accuracy: 0.6234\n",
      "Epoch 60/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6742 - accuracy: 0.7166 - val_loss: 0.8270 - val_accuracy: 0.6558\n",
      "Epoch 61/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6770 - accuracy: 0.7296 - val_loss: 0.7977 - val_accuracy: 0.6688\n",
      "Epoch 62/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6376 - accuracy: 0.7720 - val_loss: 0.8435 - val_accuracy: 0.6429\n",
      "Epoch 63/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6303 - accuracy: 0.7541 - val_loss: 0.8350 - val_accuracy: 0.6818\n",
      "Epoch 64/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6526 - accuracy: 0.7427 - val_loss: 0.8210 - val_accuracy: 0.6494\n",
      "Epoch 65/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6277 - accuracy: 0.7573 - val_loss: 0.8331 - val_accuracy: 0.6364\n",
      "Epoch 66/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6196 - accuracy: 0.7752 - val_loss: 0.8019 - val_accuracy: 0.6623\n",
      "Epoch 67/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6144 - accuracy: 0.7655 - val_loss: 0.8115 - val_accuracy: 0.6688\n",
      "Epoch 68/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6094 - accuracy: 0.7687 - val_loss: 0.7825 - val_accuracy: 0.6429\n",
      "Epoch 69/550\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.6082 - accuracy: 0.7704 - val_loss: 0.8555 - val_accuracy: 0.6169\n",
      "Epoch 70/550\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.5817 - accuracy: 0.7883 - val_loss: 0.8137 - val_accuracy: 0.6494\n",
      "Epoch 71/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.5858 - accuracy: 0.7818 - val_loss: 0.8049 - val_accuracy: 0.6623\n",
      "Epoch 72/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.5616 - accuracy: 0.7834 - val_loss: 0.7679 - val_accuracy: 0.6753\n",
      "Epoch 73/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.5605 - accuracy: 0.7883 - val_loss: 0.8235 - val_accuracy: 0.6558\n",
      "Epoch 74/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.5672 - accuracy: 0.7736 - val_loss: 0.7895 - val_accuracy: 0.6494\n",
      "Epoch 75/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.5763 - accuracy: 0.7769 - val_loss: 0.7372 - val_accuracy: 0.6818\n",
      "Epoch 76/550\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.5421 - accuracy: 0.8062 - val_loss: 0.7738 - val_accuracy: 0.6948\n",
      "Epoch 77/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.5369 - accuracy: 0.7850 - val_loss: 0.7696 - val_accuracy: 0.6948\n",
      "Epoch 78/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.5262 - accuracy: 0.8029 - val_loss: 0.8089 - val_accuracy: 0.6623\n",
      "Epoch 79/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.5510 - accuracy: 0.7915 - val_loss: 0.7783 - val_accuracy: 0.6688\n",
      "Epoch 80/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.5284 - accuracy: 0.8013 - val_loss: 0.8127 - val_accuracy: 0.6299\n",
      "Epoch 81/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.4923 - accuracy: 0.8355 - val_loss: 0.8470 - val_accuracy: 0.6169\n",
      "Epoch 82/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.5207 - accuracy: 0.8208 - val_loss: 0.7513 - val_accuracy: 0.6623\n",
      "Epoch 83/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.5075 - accuracy: 0.8143 - val_loss: 0.7809 - val_accuracy: 0.6429\n",
      "Epoch 84/550\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.4758 - accuracy: 0.8306 - val_loss: 0.7434 - val_accuracy: 0.6883\n",
      "Epoch 85/550\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.4769 - accuracy: 0.8420 - val_loss: 0.7523 - val_accuracy: 0.6688\n",
      "Epoch 86/550\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.4706 - accuracy: 0.8322 - val_loss: 0.8094 - val_accuracy: 0.6753\n",
      "Epoch 87/550\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.4575 - accuracy: 0.8290 - val_loss: 0.7940 - val_accuracy: 0.6623\n",
      "Epoch 88/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.4570 - accuracy: 0.8404 - val_loss: 0.7232 - val_accuracy: 0.7013\n",
      "Epoch 89/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.4458 - accuracy: 0.8388 - val_loss: 0.7435 - val_accuracy: 0.6883\n",
      "Epoch 90/550\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.4581 - accuracy: 0.8469 - val_loss: 0.7502 - val_accuracy: 0.7013\n",
      "Epoch 91/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.4510 - accuracy: 0.8485 - val_loss: 0.6858 - val_accuracy: 0.6948\n",
      "Epoch 92/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.4283 - accuracy: 0.8518 - val_loss: 0.7267 - val_accuracy: 0.6818\n",
      "Epoch 93/550\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.4257 - accuracy: 0.8436 - val_loss: 0.7175 - val_accuracy: 0.6818\n",
      "Epoch 94/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.4239 - accuracy: 0.8485 - val_loss: 0.7293 - val_accuracy: 0.6753\n",
      "Epoch 95/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.4279 - accuracy: 0.8485 - val_loss: 0.7359 - val_accuracy: 0.6818\n",
      "Epoch 96/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.4188 - accuracy: 0.8599 - val_loss: 0.6979 - val_accuracy: 0.7143\n",
      "Epoch 97/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.3974 - accuracy: 0.8583 - val_loss: 0.7333 - val_accuracy: 0.7013\n",
      "Epoch 98/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.4127 - accuracy: 0.8371 - val_loss: 0.7049 - val_accuracy: 0.7143\n",
      "Epoch 99/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.3766 - accuracy: 0.8713 - val_loss: 0.7061 - val_accuracy: 0.7273\n",
      "Epoch 100/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.3819 - accuracy: 0.8648 - val_loss: 0.7651 - val_accuracy: 0.7013\n",
      "Epoch 101/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.3776 - accuracy: 0.8681 - val_loss: 0.7540 - val_accuracy: 0.6558\n",
      "Epoch 102/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.3726 - accuracy: 0.8713 - val_loss: 0.7773 - val_accuracy: 0.6623\n",
      "Epoch 103/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.3740 - accuracy: 0.8827 - val_loss: 0.7119 - val_accuracy: 0.6883\n",
      "Epoch 104/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.3540 - accuracy: 0.8681 - val_loss: 0.7571 - val_accuracy: 0.6883\n",
      "Epoch 105/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.3445 - accuracy: 0.8779 - val_loss: 0.6778 - val_accuracy: 0.7273\n",
      "Epoch 106/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.3456 - accuracy: 0.8762 - val_loss: 0.7423 - val_accuracy: 0.6429\n",
      "Epoch 107/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.3509 - accuracy: 0.8827 - val_loss: 0.7906 - val_accuracy: 0.6688\n",
      "Epoch 108/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.3380 - accuracy: 0.8876 - val_loss: 0.6810 - val_accuracy: 0.7013\n",
      "Epoch 109/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.3264 - accuracy: 0.8827 - val_loss: 0.7544 - val_accuracy: 0.6753\n",
      "Epoch 110/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.3331 - accuracy: 0.8795 - val_loss: 0.7766 - val_accuracy: 0.6883\n",
      "Epoch 111/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.3124 - accuracy: 0.8974 - val_loss: 0.7944 - val_accuracy: 0.6623\n",
      "Epoch 112/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.3293 - accuracy: 0.8779 - val_loss: 0.7158 - val_accuracy: 0.7078\n",
      "Epoch 113/550\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.3362 - accuracy: 0.8779 - val_loss: 0.7186 - val_accuracy: 0.7078\n",
      "Epoch 114/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2917 - accuracy: 0.9055 - val_loss: 0.7231 - val_accuracy: 0.7078\n",
      "Epoch 115/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2898 - accuracy: 0.9055 - val_loss: 0.7896 - val_accuracy: 0.6753\n",
      "Epoch 116/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2998 - accuracy: 0.8958 - val_loss: 0.6859 - val_accuracy: 0.6753\n",
      "Epoch 117/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2941 - accuracy: 0.9039 - val_loss: 0.6790 - val_accuracy: 0.7208\n",
      "Epoch 118/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2846 - accuracy: 0.9137 - val_loss: 0.6717 - val_accuracy: 0.7597\n",
      "Epoch 119/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2674 - accuracy: 0.9169 - val_loss: 0.7345 - val_accuracy: 0.6818\n",
      "Epoch 120/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.2748 - accuracy: 0.9137 - val_loss: 0.6726 - val_accuracy: 0.7273\n",
      "Epoch 121/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2563 - accuracy: 0.9381 - val_loss: 0.9010 - val_accuracy: 0.6169\n",
      "Epoch 122/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2850 - accuracy: 0.9088 - val_loss: 0.7368 - val_accuracy: 0.6883\n",
      "Epoch 123/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.2613 - accuracy: 0.9251 - val_loss: 0.7965 - val_accuracy: 0.6883\n",
      "Epoch 124/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2661 - accuracy: 0.9153 - val_loss: 0.6921 - val_accuracy: 0.7013\n",
      "Epoch 125/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2548 - accuracy: 0.9169 - val_loss: 0.6698 - val_accuracy: 0.7532\n",
      "Epoch 126/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2272 - accuracy: 0.9316 - val_loss: 0.6816 - val_accuracy: 0.7273\n",
      "Epoch 127/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2414 - accuracy: 0.9218 - val_loss: 0.7292 - val_accuracy: 0.6948\n",
      "Epoch 128/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2449 - accuracy: 0.9300 - val_loss: 0.6665 - val_accuracy: 0.7532\n",
      "Epoch 129/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.2179 - accuracy: 0.9397 - val_loss: 0.7754 - val_accuracy: 0.7273\n",
      "Epoch 130/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2173 - accuracy: 0.9283 - val_loss: 0.7322 - val_accuracy: 0.6948\n",
      "Epoch 131/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2151 - accuracy: 0.9365 - val_loss: 0.7234 - val_accuracy: 0.7078\n",
      "Epoch 132/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2199 - accuracy: 0.9235 - val_loss: 0.7293 - val_accuracy: 0.6883\n",
      "Epoch 133/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2213 - accuracy: 0.9251 - val_loss: 0.6609 - val_accuracy: 0.7338\n",
      "Epoch 134/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2103 - accuracy: 0.9397 - val_loss: 0.8016 - val_accuracy: 0.6688\n",
      "Epoch 135/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2025 - accuracy: 0.9397 - val_loss: 0.6696 - val_accuracy: 0.7338\n",
      "Epoch 136/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1890 - accuracy: 0.9511 - val_loss: 0.6664 - val_accuracy: 0.7403\n",
      "Epoch 137/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1739 - accuracy: 0.9560 - val_loss: 0.7266 - val_accuracy: 0.7273\n",
      "Epoch 138/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1924 - accuracy: 0.9463 - val_loss: 0.6892 - val_accuracy: 0.7338\n",
      "Epoch 139/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1962 - accuracy: 0.9365 - val_loss: 0.7452 - val_accuracy: 0.6818\n",
      "Epoch 140/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1744 - accuracy: 0.9446 - val_loss: 0.6922 - val_accuracy: 0.7403\n",
      "Epoch 141/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2017 - accuracy: 0.9218 - val_loss: 0.8038 - val_accuracy: 0.6948\n",
      "Epoch 142/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1770 - accuracy: 0.9479 - val_loss: 0.7991 - val_accuracy: 0.7403\n",
      "Epoch 143/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1712 - accuracy: 0.9446 - val_loss: 0.8212 - val_accuracy: 0.7013\n",
      "Epoch 144/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1797 - accuracy: 0.9414 - val_loss: 0.7294 - val_accuracy: 0.7143\n",
      "Epoch 145/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1818 - accuracy: 0.9446 - val_loss: 0.6840 - val_accuracy: 0.7532\n",
      "Epoch 146/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1610 - accuracy: 0.9544 - val_loss: 0.6884 - val_accuracy: 0.7403\n",
      "Epoch 147/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1839 - accuracy: 0.9414 - val_loss: 0.6976 - val_accuracy: 0.7403\n",
      "Epoch 148/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1428 - accuracy: 0.9674 - val_loss: 0.7028 - val_accuracy: 0.7143\n",
      "Epoch 149/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1508 - accuracy: 0.9577 - val_loss: 0.7492 - val_accuracy: 0.7208\n",
      "Epoch 150/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1591 - accuracy: 0.9511 - val_loss: 0.8863 - val_accuracy: 0.7208\n",
      "Epoch 151/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1501 - accuracy: 0.9609 - val_loss: 0.6582 - val_accuracy: 0.7532\n",
      "Epoch 152/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1588 - accuracy: 0.9495 - val_loss: 0.6851 - val_accuracy: 0.7532\n",
      "Epoch 153/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1246 - accuracy: 0.9674 - val_loss: 0.6972 - val_accuracy: 0.7727\n",
      "Epoch 154/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1504 - accuracy: 0.9593 - val_loss: 0.6892 - val_accuracy: 0.7532\n",
      "Epoch 155/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1389 - accuracy: 0.9609 - val_loss: 0.6998 - val_accuracy: 0.7338\n",
      "Epoch 156/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1262 - accuracy: 0.9658 - val_loss: 0.7169 - val_accuracy: 0.7078\n",
      "Epoch 157/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1324 - accuracy: 0.9560 - val_loss: 0.7636 - val_accuracy: 0.7208\n",
      "Epoch 158/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1242 - accuracy: 0.9674 - val_loss: 0.8034 - val_accuracy: 0.6948\n",
      "Epoch 159/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1298 - accuracy: 0.9658 - val_loss: 0.7968 - val_accuracy: 0.7792\n",
      "Epoch 160/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1115 - accuracy: 0.9691 - val_loss: 0.8128 - val_accuracy: 0.7532\n",
      "Epoch 161/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1159 - accuracy: 0.9658 - val_loss: 0.7439 - val_accuracy: 0.7727\n",
      "Epoch 162/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.1267 - accuracy: 0.9511 - val_loss: 0.7225 - val_accuracy: 0.7273\n",
      "Epoch 163/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0981 - accuracy: 0.9788 - val_loss: 0.7392 - val_accuracy: 0.7273\n",
      "Epoch 164/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1116 - accuracy: 0.9723 - val_loss: 0.7196 - val_accuracy: 0.7532\n",
      "Epoch 165/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1043 - accuracy: 0.9707 - val_loss: 0.7183 - val_accuracy: 0.7857\n",
      "Epoch 166/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0926 - accuracy: 0.9756 - val_loss: 0.7363 - val_accuracy: 0.7208\n",
      "Epoch 167/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0842 - accuracy: 0.9821 - val_loss: 0.7021 - val_accuracy: 0.7597\n",
      "Epoch 168/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1044 - accuracy: 0.9691 - val_loss: 0.7221 - val_accuracy: 0.7468\n",
      "Epoch 169/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0890 - accuracy: 0.9723 - val_loss: 0.7228 - val_accuracy: 0.7727\n",
      "Epoch 170/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1047 - accuracy: 0.9788 - val_loss: 0.9404 - val_accuracy: 0.6948\n",
      "Epoch 171/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0856 - accuracy: 0.9821 - val_loss: 0.7697 - val_accuracy: 0.7403\n",
      "Epoch 172/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0975 - accuracy: 0.9723 - val_loss: 0.7284 - val_accuracy: 0.7597\n",
      "Epoch 173/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0896 - accuracy: 0.9788 - val_loss: 0.7781 - val_accuracy: 0.7403\n",
      "Epoch 174/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0721 - accuracy: 0.9837 - val_loss: 0.7578 - val_accuracy: 0.7403\n",
      "Epoch 175/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0828 - accuracy: 0.9821 - val_loss: 0.8171 - val_accuracy: 0.7143\n",
      "Epoch 176/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0886 - accuracy: 0.9739 - val_loss: 0.7596 - val_accuracy: 0.7078\n",
      "Epoch 177/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0699 - accuracy: 0.9870 - val_loss: 0.7310 - val_accuracy: 0.7792\n",
      "Epoch 178/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0840 - accuracy: 0.9739 - val_loss: 0.7932 - val_accuracy: 0.7597\n",
      "Epoch 179/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0769 - accuracy: 0.9739 - val_loss: 0.7438 - val_accuracy: 0.7922\n",
      "Epoch 180/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0828 - accuracy: 0.9821 - val_loss: 0.7555 - val_accuracy: 0.7597\n",
      "Epoch 181/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0799 - accuracy: 0.9821 - val_loss: 0.7539 - val_accuracy: 0.7857\n",
      "Epoch 182/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0735 - accuracy: 0.9821 - val_loss: 0.7826 - val_accuracy: 0.7468\n",
      "Epoch 183/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0649 - accuracy: 0.9821 - val_loss: 0.8032 - val_accuracy: 0.7338\n",
      "Epoch 184/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0676 - accuracy: 0.9870 - val_loss: 0.8700 - val_accuracy: 0.7597\n",
      "Epoch 185/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0604 - accuracy: 0.9853 - val_loss: 0.7656 - val_accuracy: 0.7727\n",
      "Epoch 186/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0739 - accuracy: 0.9837 - val_loss: 0.8114 - val_accuracy: 0.7987\n",
      "Epoch 187/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0569 - accuracy: 0.9886 - val_loss: 0.7759 - val_accuracy: 0.7597\n",
      "Epoch 188/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0579 - accuracy: 0.9870 - val_loss: 0.7865 - val_accuracy: 0.7727\n",
      "Epoch 189/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0486 - accuracy: 0.9886 - val_loss: 0.8441 - val_accuracy: 0.7013\n",
      "Epoch 190/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0692 - accuracy: 0.9821 - val_loss: 0.8133 - val_accuracy: 0.7468\n",
      "Epoch 191/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0588 - accuracy: 0.9919 - val_loss: 0.8490 - val_accuracy: 0.7338\n",
      "Epoch 192/550\n",
      "39/39 [==============================] - 1s 12ms/step - loss: 0.0615 - accuracy: 0.9870 - val_loss: 0.8388 - val_accuracy: 0.7208\n",
      "Epoch 193/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0630 - accuracy: 0.9853 - val_loss: 0.7781 - val_accuracy: 0.7922\n",
      "Epoch 194/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0594 - accuracy: 0.9853 - val_loss: 0.8142 - val_accuracy: 0.7273\n",
      "Epoch 195/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0594 - accuracy: 0.9870 - val_loss: 0.8094 - val_accuracy: 0.7403\n",
      "Epoch 196/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0460 - accuracy: 0.9919 - val_loss: 0.9000 - val_accuracy: 0.7208\n",
      "Epoch 197/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0519 - accuracy: 0.9853 - val_loss: 0.7990 - val_accuracy: 0.7792\n",
      "Epoch 198/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0504 - accuracy: 0.9837 - val_loss: 0.7944 - val_accuracy: 0.7727\n",
      "Epoch 199/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0512 - accuracy: 0.9935 - val_loss: 0.8238 - val_accuracy: 0.7597\n",
      "Epoch 200/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0570 - accuracy: 0.9870 - val_loss: 0.7973 - val_accuracy: 0.7532\n",
      "Epoch 201/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0512 - accuracy: 0.9886 - val_loss: 0.8185 - val_accuracy: 0.7403\n",
      "Epoch 202/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0456 - accuracy: 0.9886 - val_loss: 0.8359 - val_accuracy: 0.7727\n",
      "Epoch 203/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0400 - accuracy: 0.9870 - val_loss: 0.8456 - val_accuracy: 0.7403\n",
      "Epoch 204/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0394 - accuracy: 0.9886 - val_loss: 0.9053 - val_accuracy: 0.7403\n",
      "Epoch 205/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0460 - accuracy: 0.9837 - val_loss: 0.8572 - val_accuracy: 0.7403\n",
      "Epoch 206/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0379 - accuracy: 0.9935 - val_loss: 0.9196 - val_accuracy: 0.7987\n",
      "Epoch 207/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0307 - accuracy: 0.9951 - val_loss: 0.9573 - val_accuracy: 0.6948\n",
      "Epoch 208/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0485 - accuracy: 0.9919 - val_loss: 0.9965 - val_accuracy: 0.7338\n",
      "Epoch 209/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0365 - accuracy: 0.9935 - val_loss: 0.8013 - val_accuracy: 0.7857\n",
      "Epoch 210/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0403 - accuracy: 0.9902 - val_loss: 0.9401 - val_accuracy: 0.7727\n",
      "Epoch 211/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0397 - accuracy: 0.9919 - val_loss: 0.8771 - val_accuracy: 0.7792\n",
      "Epoch 212/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0407 - accuracy: 0.9902 - val_loss: 0.8730 - val_accuracy: 0.7532\n",
      "Epoch 213/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0331 - accuracy: 0.9919 - val_loss: 0.9839 - val_accuracy: 0.7013\n",
      "Epoch 214/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0284 - accuracy: 0.9935 - val_loss: 0.8698 - val_accuracy: 0.7468\n",
      "Epoch 215/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.8973 - val_accuracy: 0.7597\n",
      "Epoch 216/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0326 - accuracy: 0.9935 - val_loss: 0.8513 - val_accuracy: 0.7857\n",
      "Epoch 217/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0452 - accuracy: 0.9853 - val_loss: 0.9620 - val_accuracy: 0.6948\n",
      "Epoch 218/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0332 - accuracy: 0.9935 - val_loss: 0.9990 - val_accuracy: 0.7013\n",
      "Epoch 219/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0233 - accuracy: 0.9984 - val_loss: 0.9981 - val_accuracy: 0.7532\n",
      "Epoch 220/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0330 - accuracy: 0.9919 - val_loss: 0.9779 - val_accuracy: 0.7338\n",
      "Epoch 221/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0391 - accuracy: 0.9935 - val_loss: 0.9571 - val_accuracy: 0.7403\n",
      "Epoch 222/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0255 - accuracy: 0.9951 - val_loss: 0.9203 - val_accuracy: 0.7727\n",
      "Epoch 223/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0270 - accuracy: 0.9935 - val_loss: 0.8940 - val_accuracy: 0.7987\n",
      "Epoch 224/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0214 - accuracy: 0.9967 - val_loss: 0.9011 - val_accuracy: 0.7662\n",
      "Epoch 225/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0185 - accuracy: 0.9984 - val_loss: 0.9459 - val_accuracy: 0.7857\n",
      "Epoch 226/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0295 - accuracy: 0.9902 - val_loss: 0.9001 - val_accuracy: 0.7727\n",
      "Epoch 227/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0425 - accuracy: 0.9886 - val_loss: 1.0358 - val_accuracy: 0.7532\n",
      "Epoch 228/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0243 - accuracy: 0.9967 - val_loss: 1.0005 - val_accuracy: 0.7403\n",
      "Epoch 229/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0302 - accuracy: 0.9919 - val_loss: 0.9596 - val_accuracy: 0.7273\n",
      "Epoch 230/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0278 - accuracy: 0.9935 - val_loss: 1.0175 - val_accuracy: 0.7273\n",
      "Epoch 231/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0335 - accuracy: 0.9935 - val_loss: 0.9870 - val_accuracy: 0.7532\n",
      "Epoch 232/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0286 - accuracy: 0.9919 - val_loss: 1.0306 - val_accuracy: 0.7208\n",
      "Epoch 233/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0312 - accuracy: 0.9902 - val_loss: 0.9577 - val_accuracy: 0.7792\n",
      "Epoch 234/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0231 - accuracy: 0.9984 - val_loss: 0.9657 - val_accuracy: 0.7468\n",
      "Epoch 235/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.9705 - val_accuracy: 0.7468\n",
      "Epoch 236/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0208 - accuracy: 0.9967 - val_loss: 0.9399 - val_accuracy: 0.7857\n",
      "Epoch 237/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0204 - accuracy: 0.9984 - val_loss: 0.9972 - val_accuracy: 0.7662\n",
      "Epoch 238/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0218 - accuracy: 0.9951 - val_loss: 0.9784 - val_accuracy: 0.7468\n",
      "Epoch 239/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0177 - accuracy: 0.9967 - val_loss: 1.0982 - val_accuracy: 0.7208\n",
      "Epoch 240/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0219 - accuracy: 0.9951 - val_loss: 0.9537 - val_accuracy: 0.8052\n",
      "Epoch 241/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0336 - accuracy: 0.9886 - val_loss: 0.9323 - val_accuracy: 0.7727\n",
      "Epoch 242/550\n",
      "39/39 [==============================] - 1s 12ms/step - loss: 0.0184 - accuracy: 0.9984 - val_loss: 0.9794 - val_accuracy: 0.7597\n",
      "Epoch 243/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0165 - accuracy: 0.9967 - val_loss: 0.9600 - val_accuracy: 0.7857\n",
      "Epoch 244/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 0.9777 - val_accuracy: 0.7468\n",
      "Epoch 245/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0186 - accuracy: 0.9984 - val_loss: 1.1262 - val_accuracy: 0.7078\n",
      "Epoch 246/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 0.9967 - val_loss: 0.9566 - val_accuracy: 0.7662\n",
      "Epoch 247/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 0.9967 - val_loss: 1.0688 - val_accuracy: 0.7468\n",
      "Epoch 248/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0175 - accuracy: 0.9967 - val_loss: 1.2197 - val_accuracy: 0.7468\n",
      "Epoch 249/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 1.0178 - val_accuracy: 0.7792\n",
      "Epoch 250/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0229 - accuracy: 0.9951 - val_loss: 1.0124 - val_accuracy: 0.7468\n",
      "Epoch 251/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.9706 - val_accuracy: 0.7662\n",
      "Epoch 252/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.9765 - val_accuracy: 0.7662\n",
      "Epoch 253/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0222 - accuracy: 0.9919 - val_loss: 1.1104 - val_accuracy: 0.7468\n",
      "Epoch 254/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0190 - accuracy: 0.9951 - val_loss: 1.0257 - val_accuracy: 0.7532\n",
      "Epoch 255/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 1.0192 - val_accuracy: 0.7727\n",
      "Epoch 256/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 1.0380 - val_accuracy: 0.7792\n",
      "Epoch 257/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.0518 - val_accuracy: 0.7597\n",
      "Epoch 258/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 0.9967 - val_loss: 1.0320 - val_accuracy: 0.7338\n",
      "Epoch 259/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0184 - accuracy: 0.9951 - val_loss: 1.0070 - val_accuracy: 0.7532\n",
      "Epoch 260/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 1.0196 - val_accuracy: 0.7662\n",
      "Epoch 261/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.0911 - val_accuracy: 0.7403\n",
      "Epoch 262/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0178 - accuracy: 0.9919 - val_loss: 1.0290 - val_accuracy: 0.7338\n",
      "Epoch 263/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 1.1039 - val_accuracy: 0.7273\n",
      "Epoch 264/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0074 - accuracy: 0.9984 - val_loss: 1.0419 - val_accuracy: 0.7727\n",
      "Epoch 265/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.0594 - val_accuracy: 0.7922\n",
      "Epoch 266/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0125 - accuracy: 0.9967 - val_loss: 1.3398 - val_accuracy: 0.7273\n",
      "Epoch 267/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.0649 - val_accuracy: 0.7662\n",
      "Epoch 268/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0169 - accuracy: 0.9967 - val_loss: 1.0466 - val_accuracy: 0.7597\n",
      "Epoch 269/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0137 - accuracy: 0.9967 - val_loss: 1.0214 - val_accuracy: 0.7987\n",
      "Epoch 270/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.0712 - val_accuracy: 0.7468\n",
      "Epoch 271/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0121 - accuracy: 0.9967 - val_loss: 1.2653 - val_accuracy: 0.6948\n",
      "Epoch 272/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0130 - accuracy: 0.9951 - val_loss: 1.0962 - val_accuracy: 0.7857\n",
      "Epoch 273/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 1.0550 - val_accuracy: 0.7922\n",
      "Epoch 274/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0191 - accuracy: 0.9919 - val_loss: 1.0518 - val_accuracy: 0.7987\n",
      "Epoch 275/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0093 - accuracy: 0.9984 - val_loss: 1.0696 - val_accuracy: 0.7597\n",
      "Epoch 276/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9967 - val_loss: 1.0652 - val_accuracy: 0.7597\n",
      "Epoch 277/550\n",
      "39/39 [==============================] - 1s 12ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.1845 - val_accuracy: 0.7078\n",
      "Epoch 278/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0417 - accuracy: 0.9935 - val_loss: 1.1310 - val_accuracy: 0.7273\n",
      "Epoch 279/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0105 - accuracy: 0.9984 - val_loss: 1.1359 - val_accuracy: 0.7468\n",
      "Epoch 280/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 1.1985 - val_accuracy: 0.7597\n",
      "Epoch 281/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0176 - accuracy: 0.9919 - val_loss: 1.0413 - val_accuracy: 0.7987\n",
      "Epoch 282/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 1.0069 - val_accuracy: 0.7922\n",
      "Epoch 283/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 1.1005 - val_accuracy: 0.7792\n",
      "Epoch 284/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.1262 - val_accuracy: 0.7662\n",
      "Epoch 285/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0127 - accuracy: 0.9967 - val_loss: 1.1844 - val_accuracy: 0.7857\n",
      "Epoch 286/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1522 - val_accuracy: 0.7468\n",
      "Epoch 287/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 1.0809 - val_accuracy: 0.7792\n",
      "Epoch 288/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.0933 - val_accuracy: 0.7857\n",
      "Epoch 289/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 1.1009 - val_accuracy: 0.7792\n",
      "Epoch 290/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0131 - accuracy: 0.9967 - val_loss: 1.0465 - val_accuracy: 0.8052\n",
      "Epoch 291/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.2329 - val_accuracy: 0.7338\n",
      "Epoch 292/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0186 - accuracy: 0.9967 - val_loss: 1.1185 - val_accuracy: 0.7468\n",
      "Epoch 293/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 1.1111 - val_accuracy: 0.7727\n",
      "Epoch 294/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.0993 - val_accuracy: 0.7727\n",
      "Epoch 295/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.1361 - val_accuracy: 0.7532\n",
      "Epoch 296/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0121 - accuracy: 0.9951 - val_loss: 1.1571 - val_accuracy: 0.7597\n",
      "Epoch 297/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 1.0759 - val_accuracy: 0.7727\n",
      "Epoch 298/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0090 - accuracy: 0.9984 - val_loss: 1.0736 - val_accuracy: 0.7987\n",
      "Epoch 299/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 1.0500 - val_accuracy: 0.7792\n",
      "Epoch 300/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0092 - accuracy: 0.9984 - val_loss: 1.0899 - val_accuracy: 0.7727\n",
      "Epoch 301/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.4533 - val_accuracy: 0.7662\n",
      "Epoch 302/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 1.2079 - val_accuracy: 0.7208\n",
      "Epoch 303/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1025 - val_accuracy: 0.7857\n",
      "Epoch 304/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.4080 - val_accuracy: 0.7013\n",
      "Epoch 305/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 1.0935 - val_accuracy: 0.7857\n",
      "Epoch 306/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0257 - accuracy: 0.9984 - val_loss: 1.1218 - val_accuracy: 0.7792\n",
      "Epoch 307/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0143 - accuracy: 0.9967 - val_loss: 1.0747 - val_accuracy: 0.7922\n",
      "Epoch 308/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.9967 - val_loss: 1.1372 - val_accuracy: 0.7922\n",
      "Epoch 309/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.1559 - val_accuracy: 0.7727\n",
      "Epoch 310/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 1.1058 - val_accuracy: 0.7857\n",
      "Epoch 311/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.0900 - val_accuracy: 0.7662\n",
      "Epoch 312/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.1745 - val_accuracy: 0.7727\n",
      "Epoch 313/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 1.2370 - val_accuracy: 0.7662\n",
      "Epoch 314/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 1.1760 - val_accuracy: 0.7662\n",
      "Epoch 315/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.1831 - val_accuracy: 0.7597\n",
      "Epoch 316/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9935 - val_loss: 1.1766 - val_accuracy: 0.7532\n",
      "Epoch 317/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2088 - val_accuracy: 0.7792\n",
      "Epoch 318/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.9967 - val_loss: 1.2414 - val_accuracy: 0.7597\n",
      "Epoch 319/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1548 - val_accuracy: 0.7792\n",
      "Epoch 320/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1831 - val_accuracy: 0.7532\n",
      "Epoch 321/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.2011 - val_accuracy: 0.7597\n",
      "Epoch 322/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0067 - accuracy: 0.9967 - val_loss: 1.2934 - val_accuracy: 0.7208\n",
      "Epoch 323/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1575 - val_accuracy: 0.8117\n",
      "Epoch 324/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 1.3689 - val_accuracy: 0.7857\n",
      "Epoch 325/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0098 - accuracy: 0.9951 - val_loss: 1.2377 - val_accuracy: 0.7532\n",
      "Epoch 326/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0080 - accuracy: 0.9951 - val_loss: 1.1684 - val_accuracy: 0.7727\n",
      "Epoch 327/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1461 - val_accuracy: 0.7922\n",
      "Epoch 328/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1676 - val_accuracy: 0.8117\n",
      "Epoch 329/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0088 - accuracy: 0.9967 - val_loss: 1.4103 - val_accuracy: 0.7078\n",
      "Epoch 330/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.6739 - val_accuracy: 0.7208\n",
      "Epoch 331/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0129 - accuracy: 0.9967 - val_loss: 1.1678 - val_accuracy: 0.7662\n",
      "Epoch 332/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.2181 - val_accuracy: 0.7662\n",
      "Epoch 333/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1549 - val_accuracy: 0.7792\n",
      "Epoch 334/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0121 - accuracy: 0.9967 - val_loss: 1.2350 - val_accuracy: 0.7403\n",
      "Epoch 335/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.1651 - val_accuracy: 0.7857\n",
      "Epoch 336/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.1962 - val_accuracy: 0.7857\n",
      "Epoch 337/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 1.1782 - val_accuracy: 0.7792\n",
      "Epoch 338/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0380 - accuracy: 0.9967 - val_loss: 1.2447 - val_accuracy: 0.7532\n",
      "Epoch 339/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1899 - val_accuracy: 0.7922\n",
      "Epoch 340/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0127 - accuracy: 0.9984 - val_loss: 1.3273 - val_accuracy: 0.7468\n",
      "Epoch 341/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.9967 - val_loss: 1.2331 - val_accuracy: 0.7597\n",
      "Epoch 342/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0153 - accuracy: 0.9967 - val_loss: 1.1988 - val_accuracy: 0.7922\n",
      "Epoch 343/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2579 - val_accuracy: 0.7532\n",
      "Epoch 344/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 1.2531 - val_accuracy: 0.7662\n",
      "Epoch 345/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4711 - val_accuracy: 0.7468\n",
      "Epoch 346/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0085 - accuracy: 0.9967 - val_loss: 1.4539 - val_accuracy: 0.7532\n",
      "Epoch 347/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 1.3213 - val_accuracy: 0.7727\n",
      "Epoch 348/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2867 - val_accuracy: 0.7857\n",
      "Epoch 349/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 1.2952 - val_accuracy: 0.7532\n",
      "Epoch 350/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2977 - val_accuracy: 0.7532\n",
      "Epoch 351/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0076 - accuracy: 0.9967 - val_loss: 1.2878 - val_accuracy: 0.7532\n",
      "Epoch 352/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.2226 - val_accuracy: 0.7922\n",
      "Epoch 353/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.9951 - val_loss: 1.3437 - val_accuracy: 0.7468\n",
      "Epoch 354/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 1.2781 - val_accuracy: 0.7922\n",
      "Epoch 355/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.2532 - val_accuracy: 0.7792\n",
      "Epoch 356/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0090 - accuracy: 0.9951 - val_loss: 1.3473 - val_accuracy: 0.7532\n",
      "Epoch 357/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0257 - accuracy: 0.9984 - val_loss: 1.2973 - val_accuracy: 0.7597\n",
      "Epoch 358/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2923 - val_accuracy: 0.7597\n",
      "Epoch 359/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2525 - val_accuracy: 0.8052\n",
      "Epoch 360/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.3479 - val_accuracy: 0.7403\n",
      "Epoch 361/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2520 - val_accuracy: 0.7662\n",
      "Epoch 362/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.2329 - val_accuracy: 0.7987\n",
      "Epoch 363/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2338 - val_accuracy: 0.7857\n",
      "Epoch 364/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 1.2619 - val_accuracy: 0.7922\n",
      "Epoch 365/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.4080 - val_accuracy: 0.7338\n",
      "Epoch 366/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0105 - accuracy: 0.9951 - val_loss: 1.2210 - val_accuracy: 0.7792\n",
      "Epoch 367/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 1.3225 - val_accuracy: 0.7597\n",
      "Epoch 368/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0160 - accuracy: 0.9984 - val_loss: 1.3465 - val_accuracy: 0.7597\n",
      "Epoch 369/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.3146 - val_accuracy: 0.7857\n",
      "Epoch 370/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2899 - val_accuracy: 0.7857\n",
      "Epoch 371/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 1.3551 - val_accuracy: 0.7922\n",
      "Epoch 372/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0059 - accuracy: 0.9967 - val_loss: 1.2423 - val_accuracy: 0.7922\n",
      "Epoch 373/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3322 - val_accuracy: 0.7597\n",
      "Epoch 374/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0057 - accuracy: 0.9967 - val_loss: 1.2117 - val_accuracy: 0.8052\n",
      "Epoch 375/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3425 - val_accuracy: 0.7922\n",
      "Epoch 376/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.5201 - val_accuracy: 0.7273\n",
      "Epoch 377/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 9.4340e-04 - accuracy: 1.0000 - val_loss: 1.3432 - val_accuracy: 0.7662\n",
      "Epoch 378/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 7.3564e-04 - accuracy: 1.0000 - val_loss: 1.3532 - val_accuracy: 0.8182\n",
      "Epoch 379/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3979 - val_accuracy: 0.7532\n",
      "Epoch 380/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.4594 - val_accuracy: 0.7403\n",
      "Epoch 381/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.2972 - val_accuracy: 0.7662\n",
      "Epoch 382/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2648 - val_accuracy: 0.7857\n",
      "Epoch 383/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0189 - accuracy: 0.9984 - val_loss: 1.3396 - val_accuracy: 0.7662\n",
      "Epoch 384/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3049 - val_accuracy: 0.7987\n",
      "Epoch 385/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0103 - accuracy: 0.9984 - val_loss: 1.4094 - val_accuracy: 0.7597\n",
      "Epoch 386/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3808 - val_accuracy: 0.7727\n",
      "Epoch 387/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 8.1207e-04 - accuracy: 1.0000 - val_loss: 1.3216 - val_accuracy: 0.7857\n",
      "Epoch 388/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 1.4349 - val_accuracy: 0.7987\n",
      "Epoch 389/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.5566 - val_accuracy: 0.7597\n",
      "Epoch 390/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4806 - val_accuracy: 0.7922\n",
      "Epoch 391/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3002 - val_accuracy: 0.7922\n",
      "Epoch 392/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0021 - accuracy: 0.9984 - val_loss: 1.6775 - val_accuracy: 0.7078\n",
      "Epoch 393/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0023 - accuracy: 0.9984 - val_loss: 1.3544 - val_accuracy: 0.7857\n",
      "Epoch 394/550\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.4871 - val_accuracy: 0.7922\n",
      "Epoch 395/550\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 1.4303 - val_accuracy: 0.7662\n",
      "Epoch 396/550\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.0068 - accuracy: 0.9967 - val_loss: 1.7082 - val_accuracy: 0.7143\n",
      "Epoch 397/550\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.5206 - val_accuracy: 0.7727\n",
      "Epoch 398/550\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 6.8367e-04 - accuracy: 1.0000 - val_loss: 1.5565 - val_accuracy: 0.7338\n",
      "Epoch 399/550\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.6015 - val_accuracy: 0.7662\n",
      "Epoch 400/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 1.3747 - val_accuracy: 0.7792\n",
      "Epoch 401/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 9.4303e-04 - accuracy: 1.0000 - val_loss: 1.3961 - val_accuracy: 0.7662\n",
      "Epoch 402/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 7.7777e-04 - accuracy: 1.0000 - val_loss: 1.6813 - val_accuracy: 0.7143\n",
      "Epoch 403/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4141 - val_accuracy: 0.7662\n",
      "Epoch 404/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.6019 - val_accuracy: 0.7662\n",
      "Epoch 405/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0024 - accuracy: 0.9984 - val_loss: 1.4326 - val_accuracy: 0.7532\n",
      "Epoch 406/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 5.9209e-04 - accuracy: 1.0000 - val_loss: 1.3987 - val_accuracy: 0.7662\n",
      "Epoch 407/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0039 - accuracy: 0.9984 - val_loss: 1.4659 - val_accuracy: 0.7727\n",
      "Epoch 408/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.8409 - val_accuracy: 0.7338\n",
      "Epoch 409/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0079 - accuracy: 0.9984 - val_loss: 1.4425 - val_accuracy: 0.7792\n",
      "Epoch 410/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 4.7254e-04 - accuracy: 1.0000 - val_loss: 1.5554 - val_accuracy: 0.7727\n",
      "Epoch 411/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4481 - val_accuracy: 0.7987\n",
      "Epoch 412/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 1.5487 - val_accuracy: 0.7468\n",
      "Epoch 413/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3839 - val_accuracy: 0.7662\n",
      "Epoch 414/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 7.4117e-04 - accuracy: 1.0000 - val_loss: 1.3673 - val_accuracy: 0.8052\n",
      "Epoch 415/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 7.1612e-04 - accuracy: 1.0000 - val_loss: 1.6358 - val_accuracy: 0.7532\n",
      "Epoch 416/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0033 - accuracy: 0.9984 - val_loss: 1.3992 - val_accuracy: 0.7662\n",
      "Epoch 417/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0030 - accuracy: 0.9984 - val_loss: 1.4901 - val_accuracy: 0.7727\n",
      "Epoch 418/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0063 - accuracy: 0.9967 - val_loss: 1.5193 - val_accuracy: 0.7597\n",
      "Epoch 419/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 7.9198e-04 - accuracy: 1.0000 - val_loss: 1.6476 - val_accuracy: 0.7532\n",
      "Epoch 420/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 7.3854e-04 - accuracy: 1.0000 - val_loss: 2.1808 - val_accuracy: 0.6818\n",
      "Epoch 421/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 8.7348e-04 - accuracy: 1.0000 - val_loss: 1.5364 - val_accuracy: 0.7727\n",
      "Epoch 422/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 7.8583e-04 - accuracy: 1.0000 - val_loss: 1.5586 - val_accuracy: 0.7532\n",
      "Epoch 423/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0035 - accuracy: 0.9984 - val_loss: 1.4862 - val_accuracy: 0.7857\n",
      "Epoch 424/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 5.0958e-04 - accuracy: 1.0000 - val_loss: 1.6244 - val_accuracy: 0.7468\n",
      "Epoch 425/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0021 - accuracy: 0.9984 - val_loss: 1.3818 - val_accuracy: 0.7792\n",
      "Epoch 426/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0023 - accuracy: 0.9984 - val_loss: 1.4084 - val_accuracy: 0.7922\n",
      "Epoch 427/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 8.9419e-04 - accuracy: 1.0000 - val_loss: 1.4714 - val_accuracy: 0.7727\n",
      "Epoch 428/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 8.5677e-04 - accuracy: 1.0000 - val_loss: 1.4523 - val_accuracy: 0.7727\n",
      "Epoch 429/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0058 - accuracy: 0.9967 - val_loss: 1.3910 - val_accuracy: 0.7727\n",
      "Epoch 430/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0030 - accuracy: 0.9967 - val_loss: 1.4481 - val_accuracy: 0.7792\n",
      "Epoch 431/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 9.1371e-04 - accuracy: 1.0000 - val_loss: 1.4968 - val_accuracy: 0.7727\n",
      "Epoch 432/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3866 - val_accuracy: 0.7857\n",
      "Epoch 433/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0230 - accuracy: 0.9984 - val_loss: 1.4892 - val_accuracy: 0.7987\n",
      "Epoch 434/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.9310e-04 - accuracy: 1.0000 - val_loss: 1.4958 - val_accuracy: 0.7792\n",
      "Epoch 435/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.6717 - val_accuracy: 0.7468\n",
      "Epoch 436/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4528 - val_accuracy: 0.7662\n",
      "Epoch 437/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.5838 - val_accuracy: 0.7662\n",
      "Epoch 438/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 6.2257e-04 - accuracy: 1.0000 - val_loss: 1.7350 - val_accuracy: 0.7597\n",
      "Epoch 439/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0081 - accuracy: 0.9967 - val_loss: 1.4632 - val_accuracy: 0.7662\n",
      "Epoch 440/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4242 - val_accuracy: 0.8052\n",
      "Epoch 441/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0205 - accuracy: 0.9984 - val_loss: 1.5519 - val_accuracy: 0.7532\n",
      "Epoch 442/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 7.6090e-04 - accuracy: 1.0000 - val_loss: 1.5853 - val_accuracy: 0.7338\n",
      "Epoch 443/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 9.0049e-04 - accuracy: 1.0000 - val_loss: 1.6438 - val_accuracy: 0.7662\n",
      "Epoch 444/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5224 - val_accuracy: 0.7727\n",
      "Epoch 445/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 5.3266e-04 - accuracy: 1.0000 - val_loss: 1.4962 - val_accuracy: 0.7792\n",
      "Epoch 446/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 1.4688 - val_accuracy: 0.7792\n",
      "Epoch 447/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 4.6634e-04 - accuracy: 1.0000 - val_loss: 1.3859 - val_accuracy: 0.7857\n",
      "Epoch 448/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0015 - accuracy: 0.9984 - val_loss: 1.4605 - val_accuracy: 0.8052\n",
      "Epoch 449/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 6.5760e-04 - accuracy: 1.0000 - val_loss: 1.7774 - val_accuracy: 0.7208\n",
      "Epoch 450/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 5.0001e-04 - accuracy: 1.0000 - val_loss: 1.5247 - val_accuracy: 0.7857\n",
      "Epoch 451/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0045 - accuracy: 0.9967 - val_loss: 1.6010 - val_accuracy: 0.7338\n",
      "Epoch 452/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 2.2899e-04 - accuracy: 1.0000 - val_loss: 1.4954 - val_accuracy: 0.7987\n",
      "Epoch 453/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 3.8385e-04 - accuracy: 1.0000 - val_loss: 1.6813 - val_accuracy: 0.7662\n",
      "Epoch 454/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0130 - accuracy: 0.9967 - val_loss: 1.4761 - val_accuracy: 0.7987\n",
      "Epoch 455/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0031 - accuracy: 0.9984 - val_loss: 1.5924 - val_accuracy: 0.7597\n",
      "Epoch 456/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.5053 - val_accuracy: 0.7987\n",
      "Epoch 457/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 5.7762e-04 - accuracy: 1.0000 - val_loss: 1.4850 - val_accuracy: 0.7857\n",
      "Epoch 458/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0021 - accuracy: 0.9984 - val_loss: 1.4698 - val_accuracy: 0.8052\n",
      "Epoch 459/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 6.4515e-04 - accuracy: 1.0000 - val_loss: 1.6576 - val_accuracy: 0.7338\n",
      "Epoch 460/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.4099e-04 - accuracy: 1.0000 - val_loss: 1.5666 - val_accuracy: 0.7727\n",
      "Epoch 461/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 8.1375e-04 - accuracy: 1.0000 - val_loss: 1.4831 - val_accuracy: 0.7662\n",
      "Epoch 462/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 0.9984 - val_loss: 1.4656 - val_accuracy: 0.7727\n",
      "Epoch 463/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.5777 - val_accuracy: 0.7792\n",
      "Epoch 464/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.3402e-04 - accuracy: 1.0000 - val_loss: 1.5712 - val_accuracy: 0.7857\n",
      "Epoch 465/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.6113 - val_accuracy: 0.7857\n",
      "Epoch 466/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 2.6494e-04 - accuracy: 1.0000 - val_loss: 1.5860 - val_accuracy: 0.7597\n",
      "Epoch 467/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 1.4944 - val_accuracy: 0.7727\n",
      "Epoch 468/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 0.9984 - val_loss: 1.4911 - val_accuracy: 0.7792\n",
      "Epoch 469/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 5.2893e-04 - accuracy: 1.0000 - val_loss: 1.5496 - val_accuracy: 0.7532\n",
      "Epoch 470/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3885 - val_accuracy: 0.7922\n",
      "Epoch 471/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 2.4530e-04 - accuracy: 1.0000 - val_loss: 1.6438 - val_accuracy: 0.7403\n",
      "Epoch 472/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.4506 - val_accuracy: 0.7922\n",
      "Epoch 473/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 4.2801e-04 - accuracy: 1.0000 - val_loss: 1.4645 - val_accuracy: 0.7792\n",
      "Epoch 474/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4491 - val_accuracy: 0.7987\n",
      "Epoch 475/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 3.7147e-04 - accuracy: 1.0000 - val_loss: 1.5085 - val_accuracy: 0.7597\n",
      "Epoch 476/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.6500 - val_accuracy: 0.7792\n",
      "Epoch 477/550\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 1.0638e-04 - accuracy: 1.0000 - val_loss: 1.5558 - val_accuracy: 0.7857\n",
      "Epoch 478/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5034 - val_accuracy: 0.7857\n",
      "Epoch 479/550\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.0033 - accuracy: 0.9984 - val_loss: 1.4949 - val_accuracy: 0.7987\n",
      "Epoch 480/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 8.0284e-05 - accuracy: 1.0000 - val_loss: 1.5121 - val_accuracy: 0.7857\n",
      "Epoch 481/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.8841 - val_accuracy: 0.7143\n",
      "Epoch 482/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 7.3352e-04 - accuracy: 1.0000 - val_loss: 1.6318 - val_accuracy: 0.7662\n",
      "Epoch 483/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 7.1339e-04 - accuracy: 1.0000 - val_loss: 1.5638 - val_accuracy: 0.7727\n",
      "Epoch 484/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 9.9600e-04 - accuracy: 1.0000 - val_loss: 1.5803 - val_accuracy: 0.7727\n",
      "Epoch 485/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0021 - accuracy: 0.9984 - val_loss: 1.7723 - val_accuracy: 0.7468\n",
      "Epoch 486/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 3.7254e-04 - accuracy: 1.0000 - val_loss: 1.5518 - val_accuracy: 0.7987\n",
      "Epoch 487/550\n",
      "39/39 [==============================] - 1s 19ms/step - loss: 0.0036 - accuracy: 0.9984 - val_loss: 1.6211 - val_accuracy: 0.7792\n",
      "Epoch 488/550\n",
      "39/39 [==============================] - 1s 18ms/step - loss: 6.0846e-04 - accuracy: 1.0000 - val_loss: 1.4518 - val_accuracy: 0.8052\n",
      "Epoch 489/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0025 - accuracy: 0.9984 - val_loss: 1.4975 - val_accuracy: 0.8182\n",
      "Epoch 490/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 2.2445e-04 - accuracy: 1.0000 - val_loss: 1.4702 - val_accuracy: 0.7792\n",
      "Epoch 491/550\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 9.0863e-04 - accuracy: 1.0000 - val_loss: 1.4625 - val_accuracy: 0.8182\n",
      "Epoch 492/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 5.3306e-04 - accuracy: 1.0000 - val_loss: 1.5401 - val_accuracy: 0.7662\n",
      "Epoch 493/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0016 - accuracy: 0.9984 - val_loss: 1.6237 - val_accuracy: 0.7662\n",
      "Epoch 494/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 5.8550e-05 - accuracy: 1.0000 - val_loss: 1.6521 - val_accuracy: 0.7597\n",
      "Epoch 495/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 3.2189e-04 - accuracy: 1.0000 - val_loss: 1.5301 - val_accuracy: 0.8117\n",
      "Epoch 496/550\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 4.6252e-04 - accuracy: 1.0000 - val_loss: 1.5469 - val_accuracy: 0.7987\n",
      "Epoch 497/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0075 - accuracy: 0.9984 - val_loss: 1.5213 - val_accuracy: 0.7857\n",
      "Epoch 498/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 2.0341e-04 - accuracy: 1.0000 - val_loss: 1.5037 - val_accuracy: 0.7987\n",
      "Epoch 499/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.6840e-04 - accuracy: 1.0000 - val_loss: 1.5663 - val_accuracy: 0.7792\n",
      "Epoch 500/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.0021 - val_accuracy: 0.7273\n",
      "Epoch 501/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0036 - accuracy: 0.9984 - val_loss: 1.7141 - val_accuracy: 0.7532\n",
      "Epoch 502/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 2.5052e-04 - accuracy: 1.0000 - val_loss: 1.5601 - val_accuracy: 0.7792\n",
      "Epoch 503/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.5616 - val_accuracy: 0.7727\n",
      "Epoch 504/550\n",
      "39/39 [==============================] - 1s 18ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.5473 - val_accuracy: 0.7792\n",
      "Epoch 505/550\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 7.9490e-04 - accuracy: 1.0000 - val_loss: 1.5495 - val_accuracy: 0.7987\n",
      "Epoch 506/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 9.5201e-04 - accuracy: 1.0000 - val_loss: 1.7035 - val_accuracy: 0.7468\n",
      "Epoch 507/550\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 4.1512e-04 - accuracy: 1.0000 - val_loss: 2.4042 - val_accuracy: 0.7013\n",
      "Epoch 508/550\n",
      "39/39 [==============================] - 1s 18ms/step - loss: 1.5781e-04 - accuracy: 1.0000 - val_loss: 1.6864 - val_accuracy: 0.7597\n",
      "Epoch 509/550\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 1.4425 - val_accuracy: 0.7987\n",
      "Epoch 510/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 1.6184 - val_accuracy: 0.7857\n",
      "Epoch 511/550\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 3.0513e-04 - accuracy: 1.0000 - val_loss: 1.5882 - val_accuracy: 0.7857\n",
      "Epoch 512/550\n",
      "39/39 [==============================] - 1s 18ms/step - loss: 0.0024 - accuracy: 0.9984 - val_loss: 1.5910 - val_accuracy: 0.7727\n",
      "Epoch 513/550\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 3.0126e-04 - accuracy: 1.0000 - val_loss: 1.5647 - val_accuracy: 0.7857ETA: 0s - loss: 2.4860e-04 - accuracy\n",
      "Epoch 514/550\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 3.7143e-04 - accuracy: 1.0000 - val_loss: 1.9313 - val_accuracy: 0.7727\n",
      "Epoch 515/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0024 - accuracy: 0.9984 - val_loss: 1.6821 - val_accuracy: 0.7532\n",
      "Epoch 516/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.2159e-04 - accuracy: 1.0000 - val_loss: 1.8135 - val_accuracy: 0.7403\n",
      "Epoch 517/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 6.7253e-04 - accuracy: 1.0000 - val_loss: 1.5805 - val_accuracy: 0.7792\n",
      "Epoch 518/550\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 7.9304e-04 - accuracy: 1.0000 - val_loss: 1.9988 - val_accuracy: 0.7273\n",
      "Epoch 519/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0028 - accuracy: 0.9984 - val_loss: 1.6528 - val_accuracy: 0.7857\n",
      "Epoch 520/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.1854e-04 - accuracy: 1.0000 - val_loss: 1.8450 - val_accuracy: 0.7273\n",
      "Epoch 521/550\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 5.8530e-04 - accuracy: 1.0000 - val_loss: 1.7288 - val_accuracy: 0.7727\n",
      "Epoch 522/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 3.4541e-04 - accuracy: 1.0000 - val_loss: 1.8150 - val_accuracy: 0.7338\n",
      "Epoch 523/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 8.7009e-05 - accuracy: 1.0000 - val_loss: 1.9208 - val_accuracy: 0.7792\n",
      "Epoch 524/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 1.8804 - val_accuracy: 0.7273\n",
      "Epoch 525/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 1.2985e-04 - accuracy: 1.0000 - val_loss: 1.8589 - val_accuracy: 0.7403\n",
      "Epoch 526/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.9392e-04 - accuracy: 1.0000 - val_loss: 1.7336 - val_accuracy: 0.7792\n",
      "Epoch 527/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 8.8423e-04 - accuracy: 1.0000 - val_loss: 1.7294 - val_accuracy: 0.7987\n",
      "Epoch 528/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.1745 - val_accuracy: 0.7597\n",
      "Epoch 529/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 8.8111e-04 - accuracy: 1.0000 - val_loss: 1.8300 - val_accuracy: 0.7468\n",
      "Epoch 530/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0211 - accuracy: 0.9951 - val_loss: 1.7271 - val_accuracy: 0.7662\n",
      "Epoch 531/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 2.3514e-04 - accuracy: 1.0000 - val_loss: 1.6788 - val_accuracy: 0.7792\n",
      "Epoch 532/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.0557e-04 - accuracy: 1.0000 - val_loss: 1.7118 - val_accuracy: 0.7662\n",
      "Epoch 533/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 3.0703e-04 - accuracy: 1.0000 - val_loss: 1.8134 - val_accuracy: 0.7662\n",
      "Epoch 534/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0051 - accuracy: 0.9967 - val_loss: 1.8304 - val_accuracy: 0.7597\n",
      "Epoch 535/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.3739e-04 - accuracy: 1.0000 - val_loss: 1.7659 - val_accuracy: 0.7857\n",
      "Epoch 536/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0054 - accuracy: 0.9967 - val_loss: 1.7515 - val_accuracy: 0.7987\n",
      "Epoch 537/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.4829e-04 - accuracy: 1.0000 - val_loss: 1.7736 - val_accuracy: 0.7727\n",
      "Epoch 538/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.0263e-04 - accuracy: 1.0000 - val_loss: 1.7637 - val_accuracy: 0.7857\n",
      "Epoch 539/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0022 - accuracy: 0.9984 - val_loss: 1.6728 - val_accuracy: 0.7987\n",
      "Epoch 540/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.5347e-04 - accuracy: 1.0000 - val_loss: 1.8613 - val_accuracy: 0.7727\n",
      "Epoch 541/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 2.6180e-04 - accuracy: 1.0000 - val_loss: 2.0241 - val_accuracy: 0.7403\n",
      "Epoch 542/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 2.9983e-04 - accuracy: 1.0000 - val_loss: 2.3310 - val_accuracy: 0.7208\n",
      "Epoch 543/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 2.8577e-04 - accuracy: 1.0000 - val_loss: 1.9599 - val_accuracy: 0.7597\n",
      "Epoch 544/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 8.4538e-05 - accuracy: 1.0000 - val_loss: 1.7865 - val_accuracy: 0.7987\n",
      "Epoch 545/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 7.0439e-04 - accuracy: 1.0000 - val_loss: 1.8291 - val_accuracy: 0.7727\n",
      "Epoch 546/550\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.8078 - val_accuracy: 0.7727\n",
      "Epoch 547/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 1.2744e-04 - accuracy: 1.0000 - val_loss: 1.8220 - val_accuracy: 0.7857\n",
      "Epoch 548/550\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 1.3765e-04 - accuracy: 1.0000 - val_loss: 1.7528 - val_accuracy: 0.7922\n",
      "Epoch 549/550\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0031 - accuracy: 0.9984 - val_loss: 1.7266 - val_accuracy: 0.7792\n",
      "Epoch 550/550\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8451e-04 - accuracy: 1.0000 - val_loss: 1.6657 - val_accuracy: 0.7987\n"
     ]
    }
   ],
   "source": [
    "from keras import callbacks\n",
    "x_traincnn = np.asarray(x_traincnn)\n",
    "y_train = np.asarray(y_train)\n",
    "x_testcnn = np.asarray(x_testcnn)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "cnnhistory=model1.fit(x_traincnn, y_train, batch_size=16, epochs=550, validation_data=(x_testcnn, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnnhistory.history['accuracy'])\n",
    "plt.plot(cnnhistory.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajithvarma\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.89      0.88        44\n",
      "           2       0.71      0.69      0.70        36\n",
      "           5       0.82      0.82      0.82        33\n",
      "           6       0.78      0.78      0.78        41\n",
      "\n",
      "    accuracy                           0.80       154\n",
      "   macro avg       0.79      0.79      0.79       154\n",
      "weighted avg       0.80      0.80      0.80       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model1.predict_classes(x_testcnn)\n",
    "new_Ytest = y_test.astype(int)\n",
    "report = classification_report(new_Ytest, predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at /Speech Emotion\\Emotion_Voice_Detection_DCNN.h5 \n"
     ]
    }
   ],
   "source": [
    "model_name = 'Emotion_Voice_Detection_DCNN.h5'\n",
    "save_dir = '/Speech Emotion'\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model1.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
